{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías de utilidad para manipulación y visualización de datos.\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "import numpy as np\n",
    "import fastapi\n",
    "import json\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "2.6.1\n",
      "1.23.5\n",
      "0.110.1\n",
      "2.0.9\n",
      "3.2.1\n",
      "3.8.1\n",
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import pydantic\n",
    "import keras\n",
    "import nltk\n",
    "import tensorflow \n",
    "print(pd.__version__)\n",
    "print(pydantic.__version__)\n",
    "print(np.__version__)\n",
    "print(fastapi.__version__)\n",
    "print(json.__version__)\n",
    "#print(pickle.__version__)\n",
    "print(keras.__version__)\n",
    "print(nltk.__version__)\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "fastapi==0.82.0\n",
    "uvicorn==0.19.0\n",
    "pandas == 2.2.2\n",
    "pydantic == 2.6.1\n",
    "numpy==1.23.5\n",
    "json==2.0.9\n",
    "keras==3.2.1\n",
    "nltk==3.8.1\n",
    "tensorflow==2.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing railway.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile railway.json\n",
    "{\n",
    "  \"$schema\": \"https://railway.app/railway.schema.json\",\n",
    "  \"build\": {\n",
    "    \"builder\": \"NIXPACKS\"\n",
    "  },\n",
    "  \"deploy\": {\n",
    "    \"startCommand\": \"uvicorn main:app --host 0.0.0.0 --port $PORT\",\n",
    "    \"restartPolicyType\": \"ON_FAILURE\",\n",
    "    \"restartPolicyMaxRetries\": 10\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "import numpy as np\n",
    "from fastapi import FastAPI\n",
    "import json\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text])\n",
    "    tokens = word_tokenize(text)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def vectorize(X,tokenizer):\n",
    "    # Vectorización de X\n",
    "    X_vect = tokenizer.texts_to_sequences(X)\n",
    "    # Longitud vectorizada del primer elemento\n",
    "    len(X_vect)\n",
    "    # Dejamos los vectores de igual longitud\n",
    "    # Adicionamos padding en caso de ser necesario\n",
    "    max_length = 100\n",
    "    X_vect = pad_sequences(X_vect, maxlen=max_length, padding='post')\n",
    "    return X_vect\n",
    "\n",
    "\n",
    "# CLASE CALIFICADA ApiInput\n",
    "class ApiInput(BaseModel):\n",
    "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
    "    features: str\n",
    "    ### FIN DEL CÓDIGO ###\n",
    "\n",
    "# CLASE CALIFICADA ApiOutput\n",
    "class ApiOutput(BaseModel):\n",
    "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
    "    forecast: str\n",
    "    ### FIN DEL CÓDIGO ###\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Reemplace esto con su implementación:\n",
    "@app.post(\"/predict\")\n",
    "async def predict(data: ApiInput) -> ApiOutput:\n",
    "    \n",
    "    model = load_model('model_conv1d.h5') # cargamos el modelo.\n",
    "    \n",
    "    with open('labels.json', 'r') as openfile:\n",
    "        # Reading from json file\n",
    "        json_object = json.load(openfile)\n",
    "\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "    \n",
    "    input_series = pd.Series(data.features)\n",
    "    input_preprocess = input_series.apply(preprocess)\n",
    "    input_vect = vectorize(input_preprocess,tokenizer)\n",
    "    predictions = np.argmax(model.predict(input_vect),axis=1)\n",
    "    prediction = ApiOutput(forecast=list(json_object.keys())[predictions[0]])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:89: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.ApiInput'> TTC TCG CGT GTA TAG AGT GTG TGT GTG TGG GGG GGG GGC GCT CTG TGT GTG TGC GCG CGG GGA GAT ATT TTA TAT ATA TAG AGA GAG AGG GGT GTT TTG TGG GGT GTG TGC GCC CCG CGT GTA TAC ACA CAG AGC GCC CCT CTG TGC GCT CTT TTT TTG TGC GCC CCT CTA TAT ATG TGA GAA AAT ATA TAC ACT CTC TCG CGT GTT TTC TCG CGG GGC GCG CGC GCA CAA AAA AAG AGG GGG GGG GGT GTG TGT GTG TGC GCA CAG AGA GAC ACG CGG GGA GAT ATA TAC ACA CAT ATT TTT TTG TGC GCT CTG TGC GCG CGT GTC TCC CCC CCT CTA TAA AAC ACA CAC ACG CGT GTT TTC TCC CCG CGC GCC CCT CTA TAA AAT ATG\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ApiOutput(forecast='Anti_Viral')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Estructura Test 1 Funciona\n",
    "# Definimos una función para el preprocesamiento del texto convertido a trigramas (codones)\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text])\n",
    "    tokens = word_tokenize(text)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def vectorize(X,tokenizer):\n",
    "    # Vectorización de X\n",
    "    X_vect = tokenizer.texts_to_sequences(X)\n",
    "    # Longitud vectorizada del primer elemento\n",
    "    len(X_vect)\n",
    "    # Dejamos los vectores de igual longitud\n",
    "    # Adicionamos padding en caso de ser necesario\n",
    "    max_length = 100\n",
    "    X_vect = pad_sequences(X_vect, maxlen=max_length, padding='post')\n",
    "    return X_vect\n",
    "\n",
    "\n",
    "# CLASE CALIFICADA ApiInput\n",
    "class ApiInput(BaseModel):\n",
    "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
    "    features: str\n",
    "    ### FIN DEL CÓDIGO ###\n",
    "\n",
    "# CLASE CALIFICADA ApiOutput\n",
    "class ApiOutput(BaseModel):\n",
    "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
    "    forecast: str\n",
    "    ### FIN DEL CÓDIGO ###\n",
    "\n",
    "def get_api_input(features: str) -> ApiInput:\n",
    "    return ApiInput(features=features)\n",
    "\n",
    "def get_api_output(forecast: str) -> ApiOutput:\n",
    "    return ApiOutput(forecast=forecast)\n",
    "\n",
    "def predict(data: ApiInput) -> ApiOutput:\n",
    "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
    "    model = load_model('model_conv1d.h5') # cargamos el modelo.\n",
    "    \n",
    "    with open('labels.json', 'r') as openfile:\n",
    "        # Reading from json file\n",
    "        json_object = json.load(openfile)\n",
    "\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "    \n",
    "    input_series = pd.Series(data.features)\n",
    "    input_preprocess = input_series.apply(preprocess)\n",
    "    input_vect = vectorize(input_preprocess,tokenizer)\n",
    "    predictions = np.argmax(model.predict(input_vect),axis=1)\n",
    "    prediction = ApiOutput(forecast=list(json_object.keys())[predictions[0]])\n",
    "    return prediction\n",
    "\n",
    "#TEST_CELL\n",
    "test1 = \"ttc tcg cgt gta tag agt gtg tgt gtg tgg ggg ggg ggc gct ctg tgt gtg tgc gcg cgg gga gat att tta tat ata tag aga gag agg ggt gtt ttg tgg ggt gtg tgc gcc ccg cgt gta tac aca cag agc gcc cct ctg tgc gct ctt ttt ttg tgc gcc cct cta tat atg tga gaa aat ata tac act ctc tcg cgt gtt ttc tcg cgg ggc gcg cgc gca caa aaa aag agg ggg ggg ggt gtg tgt gtg tgc gca cag aga gac acg cgg gga gat ata tac aca cat att ttt ttg tgc gct ctg tgc gcg cgt gtc tcc ccc cct cta taa aac aca cac acg cgt gtt ttc tcc ccg cgc gcc cct cta taa aat atg\"\n",
    "inp = ApiInput(features=(test1.upper()))\n",
    "#inp = ApiInput(features='GGG GGT GTT TTT TTT TTG TGG GGA GAC ACT CTA TAA AAA AAA AAT ATC TCA CAA AAG AGG GGA GAG AGG GGT GTG TGG GGG GGT GTA TAA AAG AGG GGA GAG AGG GGC GCA CAG AGC GCG CGA GAA AAA AAG AGC GCG CGG GGC GCT CTG TGC GCG CGA GAA AAG AGG GGC GCA CAG AGC GCC CCG CGG GGC GCA CAA AAA AAG AGC GCC CCG CGC GCA CAT ATT TTA TAG AGG GGC GCG CGC GCC CCG CGT GTT TTT TTG TGC GCG CGA GAG AGG GGC GCA CAG AGT GTA')\n",
    "print(type(inp), inp.features)\n",
    "\n",
    "pred = predict(inp)\n",
    "display(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
